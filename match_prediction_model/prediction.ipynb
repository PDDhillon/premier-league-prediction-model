{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "matches = pd.read_csv(\"web_scraping/matches.csv\", index_col=0)\n",
    "matches.dtypes\n",
    "# create features to predict on\n",
    "matches[\"date\"] = pd.to_datetime(matches[\"date\"])\n",
    "matches[\"venue_code\"] = matches[\"venue\"].astype(\"category\").cat.codes\n",
    "matches[\"opp_code\"] = matches[\"opponent\"].astype(\"category\").cat.codes\n",
    "matches[\"hour\"] = matches[\"time\"].str.replace(\":.+\", \"\", regex=True).astype(\"int\")\n",
    "matches[\"day_code\"] = matches[\"date\"].dt.dayofweek\n",
    "\n",
    "matches[\"gf\"] = matches[\"gf\"].astype(\"int\")\n",
    "matches[\"ga\"] = matches[\"ga\"].astype(\"int\")\n",
    "# create label to predict\n",
    "matches[\"target\"] = (matches[\"result\"] == \"W\").astype(\"float\")\n",
    "\n",
    "data_df = matches[[\"venue_code\",\"opp_code\",\"hour\",\"day_code\",\"gf\",\"ga\",\"target\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FootballMatchDataset import FootballMatchDataset\n",
    "\n",
    "dataset = FootballMatchDataset(data_df)\n",
    "data_df.info()\n",
    "#type(dataset[0][1])\n",
    "#dataset[0][0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Loss:0.7121776663685871 Accuracy:0.59375\n",
      "Loss:0.696019531998259 Accuracy:0.578125\n",
      "Loss:0.6929414001481096 Accuracy:0.609375\n",
      "Epoch: 1\n",
      "Loss:0.6983984144186006 Accuracy:0.765625\n",
      "Loss:0.7129735095668117 Accuracy:0.6640625\n",
      "Loss:0.7168746597666228 Accuracy:0.6302083333333334\n",
      "Epoch: 2\n",
      "Loss:0.7066284879262341 Accuracy:0.578125\n",
      "Loss:0.7031218149404845 Accuracy:0.609375\n",
      "Loss:0.712805901076461 Accuracy:0.6197916666666666\n",
      "Epoch: 3\n",
      "Loss:0.7845220086806022 Accuracy:0.53125\n",
      "Loss:0.7691169446603857 Accuracy:0.578125\n",
      "Loss:0.759060622835047 Accuracy:0.5885416666666666\n",
      "Epoch: 4\n",
      "Loss:0.8647408708469443 Accuracy:0.609375\n",
      "Loss:0.776984077008599 Accuracy:0.5859375\n",
      "Loss:0.7534644536623646 Accuracy:0.6197916666666666\n",
      "Epoch: 5\n",
      "Loss:0.8887131359665295 Accuracy:0.625\n",
      "Loss:0.8520474714416484 Accuracy:0.578125\n",
      "Loss:0.8363649774447784 Accuracy:0.6197916666666666\n",
      "Epoch: 6\n",
      "Loss:0.8327968433491971 Accuracy:0.6875\n",
      "Loss:0.8734264119257504 Accuracy:0.6328125\n",
      "Loss:0.9724802412014292 Accuracy:0.5833333333333334\n",
      "Epoch: 7\n",
      "Loss:0.8703820612957114 Accuracy:0.65625\n",
      "Loss:0.8523911813379277 Accuracy:0.625\n",
      "Loss:0.8402910080989385 Accuracy:0.5989583333333334\n",
      "Epoch: 8\n",
      "Loss:1.0522063312167482 Accuracy:0.578125\n",
      "Loss:1.1083428380033749 Accuracy:0.609375\n",
      "Loss:1.0693980119496207 Accuracy:0.640625\n",
      "Epoch: 9\n",
      "Loss:1.1074371776079377 Accuracy:0.609375\n",
      "Loss:1.0103185477545238 Accuracy:0.609375\n",
      "Loss:1.0408722110963977 Accuracy:0.609375\n",
      "Epoch: 10\n",
      "Loss:1.0515026461241934 Accuracy:0.71875\n",
      "Loss:1.0543943058733902 Accuracy:0.6171875\n",
      "Loss:1.082596501310707 Accuracy:0.6197916666666666\n",
      "Epoch: 11\n",
      "Loss:1.2353917496872246 Accuracy:0.609375\n",
      "Loss:1.1714963159386 Accuracy:0.625\n",
      "Loss:1.2638833108644334 Accuracy:0.6041666666666666\n",
      "Epoch: 12\n",
      "Loss:1.2984020603764939 Accuracy:0.671875\n",
      "Loss:1.3398920641758219 Accuracy:0.65625\n",
      "Loss:1.3694862758972557 Accuracy:0.609375\n",
      "Epoch: 13\n",
      "Loss:1.3073731750587132 Accuracy:0.625\n",
      "Loss:1.435978620642484 Accuracy:0.609375\n",
      "Loss:1.3791217826266984 Accuracy:0.6145833333333334\n",
      "Epoch: 14\n",
      "Loss:1.1070162564721593 Accuracy:0.671875\n",
      "Loss:1.3086968790718108 Accuracy:0.625\n",
      "Loss:1.3510322140871551 Accuracy:0.609375\n",
      "Epoch: 15\n",
      "Loss:1.4829395340607898 Accuracy:0.515625\n",
      "Loss:1.4951398419274264 Accuracy:0.5390625\n",
      "Loss:1.5270277686427185 Accuracy:0.5885416666666666\n",
      "Epoch: 16\n",
      "Loss:1.1628541334141762 Accuracy:0.609375\n",
      "Loss:1.1879054762664998 Accuracy:0.5859375\n",
      "Loss:1.2400992088045244 Accuracy:0.59375\n",
      "Epoch: 17\n",
      "Loss:1.3536691216883951 Accuracy:0.53125\n",
      "Loss:1.6451774408447895 Accuracy:0.5703125\n",
      "Loss:1.6809160596087718 Accuracy:0.6145833333333334\n",
      "Epoch: 18\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\Documents\\AICore\\premier-league-prediction-model\\prediction.ipynb Cell 3\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Documents/AICore/premier-league-prediction-model/prediction.ipynb#W2sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m model \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Documents/AICore/premier-league-prediction-model/prediction.ipynb#W2sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m model\u001b[39m.\u001b[39mtrain(\u001b[39mTrue\u001b[39;00m)     \n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Documents/AICore/premier-league-prediction-model/prediction.ipynb#W2sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m trainloader:\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Documents/AICore/premier-league-prediction-model/prediction.ipynb#W2sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     \u001b[39m# get features and labels from the batch\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Documents/AICore/premier-league-prediction-model/prediction.ipynb#W2sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     features,labels \u001b[39m=\u001b[39m batch\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Documents/AICore/premier-league-prediction-model/prediction.ipynb#W2sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     features \u001b[39m=\u001b[39m features\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\epl\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_data()\n\u001b[0;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\epl\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    676\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 677\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_fetcher\u001b[39m.\u001b[39mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    678\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    679\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\epl\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\epl\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\epl\\Lib\\site-packages\\torch\\utils\\data\\dataset.py:298\u001b[0m, in \u001b[0;36mSubset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(idx, \u001b[39mlist\u001b[39m):\n\u001b[0;32m    297\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindices[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m idx]]\n\u001b[1;32m--> 298\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindices[idx]]\n",
      "File \u001b[1;32md:\\Documents\\AICore\\premier-league-prediction-model\\FootballMatchDataset.py:13\u001b[0m, in \u001b[0;36mFootballMatchDataset.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     11\u001b[0m features \u001b[39m=\u001b[39m record[:\u001b[39m6\u001b[39m]\n\u001b[0;32m     12\u001b[0m label \u001b[39m=\u001b[39m record[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m---> 13\u001b[0m \u001b[39mreturn\u001b[39;00m (torch\u001b[39m.\u001b[39mtensor(features\u001b[39m.\u001b[39mvalues), label)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from FootballMatchDataset import FootballMatchDataset\n",
    "from FootballMatchClassfier import FootballMatchClassfier\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch \n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "dataset = FootballMatchDataset(data_df)\n",
    "train_dataset,test_dataset,val_dataset = random_split(dataset, [0.7,0.2,0.1])\n",
    "\n",
    "trainloader = DataLoader(train_dataset,batch_size=64,shuffle=True,drop_last=True)\n",
    "valloader = DataLoader(val_dataset,batch_size=64,shuffle=True,drop_last=True)\n",
    "testloader = DataLoader(test_dataset,batch_size=64,shuffle=True,drop_last=True)\n",
    "\n",
    "model = FootballMatchClassfier(6)\n",
    "optimiser = torch.optim.SGD(model.parameters(), lr=0.0001)\n",
    "loss_function = torch.nn.BCELoss()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "epochs = 100\n",
    "for i in range(epochs):    \n",
    "    print(f'Epoch: {i}')\n",
    "    #writer = SummaryWriter()\n",
    "    batch_id = 0     \n",
    "    # Set the model to run on the device\n",
    "    model = model.to(device)\n",
    "    model.train(True)     \n",
    "    for batch in trainloader:\n",
    "        # get features and labels from the batch\n",
    "        features,labels = batch\n",
    "        features = features.to(device)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "        # loss.backward does not overwrite, it adds. To stop this, we set the gradients back to zero. sets the .grad of all optimized tensors to zero\n",
    "        optimiser.zero_grad()\n",
    "        # make a prediction\n",
    "        prediction = model(features)\n",
    "        # calculate loss\n",
    "        criterion = loss_function(prediction,labels.unsqueeze(1))\n",
    "        # backward function calculates the gradient of the current tensor w.r.t graph leaves\n",
    "        criterion.backward()\n",
    "        # moves each parameter in the opposite direction of the gradient, proportional to the learning rate\n",
    "        optimiser.step()\n",
    "        #writer.add_scalar('Loss', criterion.item(), batch_id)\n",
    "        batch_id += 1\n",
    "        # print(f'Batch: {batch_id}')\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_steps = 0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for i, data in enumerate(valloader, 0):\n",
    "        with torch.no_grad():\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            loss = loss_function(prediction,labels.unsqueeze(1))\n",
    "            val_loss += loss.cpu().numpy()\n",
    "            val_steps += 1            \n",
    "            print (f'Loss:{val_loss / val_steps} Accuracy:{correct / total}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "epl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
